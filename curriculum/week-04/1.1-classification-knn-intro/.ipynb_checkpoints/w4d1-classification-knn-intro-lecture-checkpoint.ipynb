{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ![](https://ga-dash.s3.amazonaws.com/production/assets/logo-9f88ae6c9c3871690e33280fcf557f33.png) Intro to Classification and kNN\n",
    "Week 4 | Lesson 1.1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### LEARNING OBJECTIVES\n",
    "*After this lesson, you will be able to:*\n",
    "- Define and give examples of classification\n",
    "- Explain the kNN algorithm\n",
    "- Build a K-Nearest Neighbors model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### LESSON GUIDE\n",
    "| TIMING  | TYPE  | TOPIC  |\n",
    "|:-:|---|---|\n",
    "| 5 min  | [Opening](#opening)  | Discuss lesson objectives |\n",
    "| 10 min  | [Introduction](#introduction)   | Description of Classification  |\n",
    "| 20 min  | [Demo](#demo)  | How kNN logically works   |\n",
    "| 50 min  | [Independent Practice](#ind-practice)  |  Build a simple kNN model  |\n",
    "| 5 min  | [Conclusion](#conclusion)  | Review / Recap |\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a name=\"opening\"></a>\n",
    "## Opening (5 mins)\n",
    "\n",
    "We've been doing regression, which is predicting to a continuous value. Now let's learn some techniques for classification: predicting to class values.\n",
    "\n",
    "> Check: what is a scenario where you would use classification? Can you convert a regression problem into a classification one?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a name=\"introduction\"></a>\n",
    "## Introduction: Topic (10 mins)\n",
    "\n",
    "Classification is a technique in machine learning of assigning a classification on new instances of data from already observed past data whose classification is known. \n",
    "\n",
    "For example, we might build a machine learning model to detect spam emails. The model would analyze the emails' content and classify them as either \"spam\" or \"legitimate\" emails.\n",
    "\n",
    "![](http://i.giphy.com/iQbUZdceDtKRG.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Many classification problems can boil down to a binary problem like this. What if you are predicting whether an image pixel will be red or blue? We could check whether a pixel \"is red\" or \"is not red.\"\n",
    "\n",
    "Binary classification is the simplest form of classification, though classification problems can certainly deal with multiple class labels.\n",
    "\n",
    "There are a number of different classification techniques, including k-Nearest Neighbors. (You'll learn about a second, logistic regression, this afternoon.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### K-Nearest Neighbors (kNN)\n",
    "\n",
    "The K-Nearest Neighbors (kNN) classification algorithm is one of the simplest. It is based on proximity to known data points with known classifications. It is surprisingly powerful, and can learn complex decision boundaries.\n",
    "\n",
    "![](http://i.giphy.com/3orieYYLakrjOsQ77i.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A case is classified by a majority vote of its neighbors, with the case being assigned to the class most common amongst its K nearest neighbors measured by a distance function.\n",
    "\n",
    "> Check: will it matter what we choose for K? If so, how do we choose?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Choosing the optimal value for K is best done by first inspecting the data. In general, a large K value is more precise as it reduces the overall noise, but there is no guarantee.\n",
    "\n",
    "Cross-validation is another way to retrospectively determine a good K value by using an independent dataset to validate the K value. Historically, the optimal K for most datasets has been between 3-10. That produces much better results than 1NN.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a name=\"demo\"></a>\n",
    "## Demo: kNN, conceptually (20 mins)\n",
    "\n",
    "Here is some pseudo-code to demonstrate how kNN works:\n",
    "\n",
    "```python\n",
    "procedure KNN(x)\n",
    "  begin\n",
    "    looping through all known data points in training data, find the closest k points to x\n",
    "    assign f(x) = majority classification among the k closest points\n",
    "  end\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Consider the following data concerning credit default. Age and Loan are two numerical variables (predictors) and Default is the target.\n",
    "\n",
    "![](./assets/images/graph1.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can now use the training set to classify an unknown case (Age = 48, Loan = $142,000) using Euclidean distance. If K = 1 then the nearest neighbor is the last case in the training set with Default=Y.\n",
    "\n",
    "> Check: what's the classification with K = 3?\n",
    "\n",
    "![](./assets/images/graph.week.4class1-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "With K=3, there are two Default=Y and one Default=N out of three closest neighbors. The prediction for the unknown case is again Default=Y.\n",
    "\n",
    "> Check: there is something very problematic about our distance calculations: do you see it? (There's also a typo in the Eucleadian distance formula...)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a name=\"ind-practice\"></a>\n",
    "## Independent Practice: Build a simple kNN model  (50 minutes)\n",
    "\n",
    "In your project 3 teams, use the structure in the lesson notebook to build out a kNN classifier.\n",
    "\n",
    "**Suggestion**: there are several independent functions to write. Start by defining what goes in and comes out of each of these, and then assign one group member to write each function.\n",
    "\n",
    "When writing a function, try to break down the problem into the smallest component pieces before you start writing real code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a name=\"conclusion\"></a>\n",
    "## Conclusion (5 mins)\n",
    "\n",
    "We can now answer and discuss these questions:\n",
    "\n",
    "- What are class labels? What does it mean to classify?\n",
    "- How does the kNN algorithm work?\n",
    "- How do you define: accuracy, misclassification?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "***\n",
    "\n",
    "### ADDITIONAL RESOURCES\n",
    "\n",
    "- [How KNN Works](https://saravananthirumuruganathan.wordpress.com/2010/05/17/a-detailed-introduction-to-k-nearest-neighbor-knn-algorithm/)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
